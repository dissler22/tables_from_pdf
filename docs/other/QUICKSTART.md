# ğŸš€ Guide de dÃ©marrage rapide

Ce guide explique comment lancer l'extracteur GMFT et produire vos premiers exports tabulaires en 5 minutes.

> â„¹ï¸ **Organisation des fichiers**  
> - Le cÅ“ur backend vit dans `backend/gmft_core/`.  
> - Les artefacts gÃ©nÃ©rÃ©s sont stockÃ©s dans `data/` (`data/uploads`, `data/layouts`, `data/tables_store`).  
> - Les PDF d'exemple se trouvent dans `tests/data/pdf_tables/`. Pensez Ã  adapter les chemins aux vÃ´tres.

## ğŸ“‹ PrÃ©requis

- Python 3.10+
- GMFT (tÃ©lÃ©chargÃ© automatiquement via submodule) + poids du modÃ¨le (`GMFT_MODEL_PATH`)
- PDF de test contenant au moins un tableau (idÃ©alement 2 pour valider multi-pages)
- Tesseract installÃ© si vous traitez des scans

## âš¡ Installation rapide

### 1. Installer les dÃ©pendances

```bash
cd backend/gmft_core
pip install -e .
pip install -r requirements-ocr.txt  # si OCR nÃ©cessaire
cd ../..
```

### 2. Configurer l'environnement

CrÃ©ez (ou complÃ©tez) `.env` Ã  la racine :

```bash
# GMFT
GMFT_MODEL_PATH=./models/gmft_large.pt
GMFT_CACHE_DIR=./.gmft_cache
GMFT_PROFILE=default

# OCR
OCR_ENGINE=tesseract
TESSDATA_PREFIX=/usr/share/tesseract-ocr/4.00/tessdata

# RÃ©fÃ©rentiels
REFS_FILE=./data/refs/refs_user.json
REFS_PROFILES_FILE=./data/refs/refs_people.json

# Stockage
TABLES_STORE=./data/tables_store
UPLOAD_DIR=./data/uploads
LAYOUT_DIR=./data/layouts

# FastAPI
API_HOST=0.0.0.0
API_PORT=9726
API_KEY=demo-key
```

### 3. Initialiser les rÃ©fÃ©rentiels

CrÃ©ez `data/refs/refs_user.json` :

```json
{
  "Direction FinanciÃ¨re": ["DirFin", "Finance centrale"],
  "BU Infrastructures": ["Infra", "Business Unit Infra"]
}
```

CrÃ©ez `data/refs/refs_people.json` pour vos profils heuristiques :

```json
{
  "__meta__": {
    "version": 1,
    "updated_at": null
  },
  "profiles": []
}
```

## ğŸ¯ Utilisation

### Ã‰tape 1 : Ingestion d'un PDF

```bash
cd backend/gmft_core
python scripts/ingest_sample.py --data ../tests/data/pdf_tables --profile default
```

**Sortie attendue** :
```
================================================================================
GMFT INGEST - Configuration
================================================================================
Data directory: ./tests/data/pdf_tables
OCR engine: tesseract
GMFT model: ./models/gmft_large.pt
================================================================================

[INFO] Found 2 PDF file(s)
   - bilan_financier.pdf (312 KB)
   - rapport_travaux.pdf (1.2 MB)

[1/2] Processing: bilan_financier.pdf
   -> Preprocessing pages (deskew, contrast, binarize)
   -> GMFT running... 3 tables detected
   -> Normalizing schema and casting columns
   [OK] Exported table_id: tbl-0c89fe...

[SUCCESS] All runs completed!
```

Chaque run crÃ©e :
- un dossier `data/layouts/<run_id>/` avec les prÃ©visualisations.
- des DataFrame dans `data/tables_store/parquet/`.

### Ã‰tape 2 : Tester les requÃªtes

**API REST** :
```bash
python -m gmft_core.api.server  # dans un terminal
```

Puis :
```bash
curl -H "X-API-Key: demo-key" \
     -X POST http://localhost:9726/tables/query \
     -H "Content-Type: application/json" \
     -d '{"filters": {"folder": "Direction FinanciÃ¨re"}}'
```

**CLI** :
```bash
cd ..
gmft-cli query --folder "Direction FinanciÃ¨re" --format csv --output ./exports
```

## ğŸ“ Exemples de requÃªtes

### 1. Recherche par dossier

```python
from gmft_extractor.client import GMFTClient

client = GMFTClient(api_key="demo-key")
result = client.query_tables(filters={"folder": "BU Infrastructures"})
```

### 2. Recherche par colonnes

```python
client.query_tables(filters={"column_set": ["Lot", "Montant HT", "TVA"]})
```

### 3. Export spÃ©cifique

```python
client.export_table(table_id="tbl-0c89fe...", fmt="parquet", output_path="./exports")
```

### 4. Rejouer un run avec un nouveau profil

```bash
python scripts/replay_run.py --run-id run-20240112-1145 --profile audit
```

## ğŸ”§ Commandes utiles

### Purger les artefacts

```bash
cd backend/gmft_core
rm -rf ./data/tables_store ./data/layouts
python scripts/ingest_sample.py
```

### Inspecter les mÃ©tadonnÃ©es

```bash
ls data/metadata/
cat data/metadata/run-20240112-1145.json | jq '.'
```

### Liste des tables

```bash
python -c "import json; data=json.load(open('data/tables_store/kv_store_tables.json')); print(len(data))"
```

### PrÃ©visualiser un tableau annotÃ©

```bash
python scripts/preview_table.py --table-id tbl-0c89fe...
```

## ğŸ› DÃ©pannage rapide

### Erreur : `GMFT_MODEL_PATH not found`
â†’ VÃ©rifier que le modÃ¨le est tÃ©lÃ©chargÃ© et que la variable pointe au bon chemin.

### Erreur : `OCR engine not available`
â†’ Installer Tesseract (`sudo apt install tesseract-ocr`) ou changer `OCR_ENGINE`.

### Tables vides
â†’ Utiliser `scripts/debug_cells.py --run-id <id>` pour inspecter les cellules brutes et ajuster le profil heuristique.

### Exports incomplets
â†’ VÃ©rifier `data/tables_store/export.log` pour les colonnes ignorÃ©es ; relancer avec `--strict-mode` pour bloquer si une colonne clÃ© manque.

## ğŸ“š Prochaines Ã©tapes

1. **Ajouter de nouveaux profils** : via `/profiles` ou `frontend/streamlit/pages/3_Gestion_heuristiques.py`.
2. **Brancher vos pipelines** : consommer les Parquet via Spark/DBT.
3. **Automatiser** : lancer `gmft-cli ingest --watch <dossier>` pour surveiller un rÃ©pertoire partagÃ©.
4. **DÃ©ployer** : dockeriser `gmft_core.api.server` + worker et connecter Prometheus/Grafana.

## ğŸ†˜ Besoin d'aide ?

- **Documentation complÃ¨te** : `README.md`
- **Architecture dÃ©taillÃ©e** : `README_adaptations.md`
- **RÃ¨gles Cursor** : `.cursorrules`

---

**Setup estimÃ©** : 5-10 minutes  
**Temps d'extraction** : ~45 s pour 50 pages  
**Temps de requÃªte** : ~1 s en mode `filtered`
